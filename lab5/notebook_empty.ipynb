{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poza standardowymi narzędziami do klasyfikacji tabelarycznej użyjemy bibliotek:\n",
    "1. [Imbalanced-learn](https://imbalanced-learn.org/stable/index.html) - biblioteka implementująca różne algorytmy undersamplingu i oversamplingu\n",
    "2. [PyOD](https://pyod.readthedocs.io/en/latest/index.html) - biblioteka implementująca mnóstwo algorytmów outlier detection\n",
    "3. [XGBoost](https://xgboost.readthedocs.io/en/stable/) - oficjalna implementacja algorytmu XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja umiarkowanie niezbalansowana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw wykorzystamy zbiór danych [Polish companies bankruptcy](https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data). Dotyczy on klasyfikacji, na podstawie danych z raportów finansowych, czy firma zbankrutuje w ciągu najbliższych kilku lat. Jest to zadanie szczególnie istotne dla banków, funduszy inwestycyjnych, firm ubezpieczeniowych itp., które z tego powodu zatrudniają licznie data scientistów. Zbiór zawiera 64 cechy, obliczone przez ekonomistów, którzy stworzyli ten zbiór, opisane na stronie UCI.\n",
    "\n",
    "Wykorzystamy podzbiór, w którym na podstawie finansowych firmy po 3 latach monitorowania chcemy przewidywać, czy firma zbankrutuje w ciągu najbliższych 3 lat. Jest to dość realistyczny horyzont czasowy, a przy tym największy z podzbiorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr55</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.41299</td>\n",
       "      <td>0.14371</td>\n",
       "      <td>1.3480</td>\n",
       "      <td>-28.9820</td>\n",
       "      <td>0.60383</td>\n",
       "      <td>0.219460</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>1.1961</td>\n",
       "      <td>0.46359</td>\n",
       "      <td>...</td>\n",
       "      <td>127280.0</td>\n",
       "      <td>0.163960</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.83604</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.7145</td>\n",
       "      <td>6.2813</td>\n",
       "      <td>84.291</td>\n",
       "      <td>4.3303</td>\n",
       "      <td>4.0341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.46038</td>\n",
       "      <td>0.28230</td>\n",
       "      <td>1.6294</td>\n",
       "      <td>2.5952</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>1.1721</td>\n",
       "      <td>1.6018</td>\n",
       "      <td>0.53962</td>\n",
       "      <td>...</td>\n",
       "      <td>3387.8</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.90108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.9882</td>\n",
       "      <td>4.1103</td>\n",
       "      <td>102.190</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>5.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.22612</td>\n",
       "      <td>0.48839</td>\n",
       "      <td>3.1599</td>\n",
       "      <td>84.8740</td>\n",
       "      <td>0.19114</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>2.9881</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>0.67566</td>\n",
       "      <td>...</td>\n",
       "      <td>20453.0</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.99236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.7742</td>\n",
       "      <td>3.7922</td>\n",
       "      <td>64.846</td>\n",
       "      <td>5.6287</td>\n",
       "      <td>4.4581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024526</td>\n",
       "      <td>0.43236</td>\n",
       "      <td>0.27546</td>\n",
       "      <td>1.7833</td>\n",
       "      <td>-10.1050</td>\n",
       "      <td>0.56944</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>1.3057</td>\n",
       "      <td>1.0509</td>\n",
       "      <td>0.56453</td>\n",
       "      <td>...</td>\n",
       "      <td>5012.6</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.142980</td>\n",
       "      <td>4.2286</td>\n",
       "      <td>5.0528</td>\n",
       "      <td>98.783</td>\n",
       "      <td>3.6950</td>\n",
       "      <td>3.4844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188290</td>\n",
       "      <td>0.41504</td>\n",
       "      <td>0.34231</td>\n",
       "      <td>1.9279</td>\n",
       "      <td>-58.2740</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.233580</td>\n",
       "      <td>1.4094</td>\n",
       "      <td>1.3393</td>\n",
       "      <td>0.58496</td>\n",
       "      <td>...</td>\n",
       "      <td>13730.0</td>\n",
       "      <td>0.176480</td>\n",
       "      <td>0.321880</td>\n",
       "      <td>0.82635</td>\n",
       "      <td>0.073039</td>\n",
       "      <td>2.5912</td>\n",
       "      <td>7.0756</td>\n",
       "      <td>100.540</td>\n",
       "      <td>3.6303</td>\n",
       "      <td>4.6375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2    Attr3   Attr4    Attr5    Attr6     Attr7   Attr8  \\\n",
       "0  0.174190  0.41299  0.14371  1.3480 -28.9820  0.60383  0.219460  1.1225   \n",
       "1  0.146240  0.46038  0.28230  1.6294   2.5952  0.00000  0.171850  1.1721   \n",
       "2  0.000595  0.22612  0.48839  3.1599  84.8740  0.19114  0.004572  2.9881   \n",
       "3  0.024526  0.43236  0.27546  1.7833 -10.1050  0.56944  0.024526  1.3057   \n",
       "4  0.188290  0.41504  0.34231  1.9279 -58.2740  0.00000  0.233580  1.4094   \n",
       "\n",
       "    Attr9   Attr10  ...    Attr55    Attr56    Attr57   Attr58    Attr59  \\\n",
       "0  1.1961  0.46359  ...  127280.0  0.163960  0.375740  0.83604  0.000007   \n",
       "1  1.6018  0.53962  ...    3387.8  0.027516  0.271000  0.90108  0.000000   \n",
       "2  1.0077  0.67566  ...   20453.0  0.007639  0.000881  0.99236  0.000000   \n",
       "3  1.0509  0.56453  ...    5012.6  0.048398  0.043445  0.95160  0.142980   \n",
       "4  1.3393  0.58496  ...   13730.0  0.176480  0.321880  0.82635  0.073039   \n",
       "\n",
       "   Attr60  Attr61   Attr62  Attr63  Attr64  \n",
       "0  9.7145  6.2813   84.291  4.3303  4.0341  \n",
       "1  5.9882  4.1103  102.190  3.5716  5.9500  \n",
       "2  6.7742  3.7922   64.846  5.6287  4.4581  \n",
       "3  4.2286  5.0528   98.783  3.6950  3.4844  \n",
       "4  2.5912  7.0756  100.540  3.6303  4.6375  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "data = arff.loadarff(\"polish_companies_bankruptcy_3_year_data.arff\")\n",
    "\n",
    "df = pd.DataFrame(data[0])\n",
    "y = df.pop(\"class\").astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (1 punkt)**\n",
    "\n",
    "1. Zwizualizuj brakujące ilość brakujących danych na wykresie słupkowym (bar plot).\n",
    "2. Zwizualizuj rozkład klas na wykresie.\n",
    "3. Usuń cechę `Attr37`, mającą dużo wartości brakujących.\n",
    "4. Dokonaj podziału na zbiór treningowy i testowy w proporcjach 75%-25%, ze stratyfikacją. Pamiętaj o `random_state=0`.\n",
    "5. Zbuduj i zastosuj pipeline (`make_pipeline`) do czyszczenia danych, składający się z:\n",
    "   - uzupełnienia wartości brakujących wartością średnią (`SimpleImputer`)\n",
    "   - standaryzacji danych (`StandardScaler`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def na_count(df):\n",
    "    plt.bar([i for i in range(df.shape[1])], df.isna().sum())\n",
    "    plt.xlabel(\"Atrribute #\")\n",
    "    plt.title(\"Missing values per Attribute\")\n",
    "    plt.semilogy()\n",
    "    plt.yticks(np.logspace(0, 4, 5))\n",
    "    plt.show()\n",
    "\n",
    "def class_distribution():\n",
    "    plt.pie(y.value_counts(), labels = [\"No\", \"Yes\"], colors = [\"blue\", \"red\"])\n",
    "    plt.title(\"Will company go bancrupt?\")\n",
    "    plt.show()\n",
    "\n",
    "na_count(df)\n",
    "class_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Attr37\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df, y, test_size=0.25, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train_raw)\n",
    "X_test = pipeline.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standaryzacja była szczególnie ważna, bo metody undersamplingu i oversamplingu są oparte o najbliższych sąsiadów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-sensitive learning i threshold tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako naszego algorytmu użyjemy lasu losowego (Random Forest). Dla przypomnienia, jest on oparty o **uczenie zespołowe (ensemble learning)**, w którym uśredniamy decyzje wielu klasyfikatorów bazowych. Są to drzewa decyzyjne. Losujemy w nim **próbki bootstrapowe (bootstrap samples)**, czyli losujemy z powtórzeniami tyle punktów, ile wynosi rozmiar naszego zbioru. Dla każdej losujemy także podzbiór cech, typowo tyle, ile wynosi pierwiastek kwadratowy z liczby wszystkich cech. Następnie trenujemy drzewa decyzyjne na takich wylosowanych podzbiorach. Decyzja klasyfikatora jest podejmowana przez głosowanie drzew (w klasyfikacji) lub ich uśrednienie (w regresji).\n",
    "\n",
    "W wielu zastosowaniach dużą zaletą lasów losowych jest ich niska podatność na tuning hiperparametrów, tzw. **tunability**. Algorytmy o wysokim tunability (np. SVM) są podatne na dobór hiperparametrów i wymagają jego zastosowania, żeby osiągnąć dobre wyniki. Random Forest działa typowo doskonale z domyślnymi hiperparametrami, co najwyżej warto czasem ustawić większą liczbę drzew, niż domyślna. Ciekawe artykuły w tej kwestii to:\n",
    "\n",
    "> Probst, Philipp, Anne-Laure Boulesteix, and Bernd Bischl. *\"Tunability: Importance of hyperparameters of machine learning algorithms.\"* The Journal of Machine Learning Research 20.1 (2019): 1934-1965. [link](https://www.jmlr.org/papers/volume20/18-444/18-444.pdf)\n",
    "\n",
    "> Probst, Philipp, Marvin N. Wright, and Anne‐Laure Boulesteix. *\"Hyperparameters and tuning strategies for random forest.\"* Wiley Interdisciplinary Reviews: data mining and knowledge discovery 9.3 (2019): e1301. [link](https://arxiv.org/pdf/1804.03515.pdf)\n",
    "\n",
    "Dzięki wykorzystaniu Random Forest zasadniczo nie będziemy potrzebować tuningu hiperparametrów dla klasyfikatora. Nadaje się też dobrze do klasyfikacji niezbalansowanej: drzewa decyzyjne łatwo integrują ważenie klas w proces treningu, a uśrednianie decyzji mocno zmniejsza wariancję błędu.\n",
    "\n",
    "Ze względu na niezbalansowanie zbioru, które jest znaczące, ale nie ekstremalne, wykorzystamy dwie metryki: AUROC oraz F1-score. Ta druga będzie przydatna przy **threshold tuningu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 84.99%\n",
      "F1-score: 11.59%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "y_pred_score = clf_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_pred_score)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "print(f\"F1-score: {100 * f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC wydaje się niezłe, ale F1-score pozostawia wiele do życzenia. Zobaczmy, czy **cost-sensitive learning** coś zmieni. Skorzystamy z domyślnej heurystyki do ważenia klas `\"balanced\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 86.81%\n",
      "F1-score: 18.31%\n"
     ]
    }
   ],
   "source": [
    "clf_rf_csl = RandomForestClassifier(class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "clf_rf_csl.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_rf_csl.predict(X_test)\n",
    "y_pred_score = clf_rf_csl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_pred_score)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "print(f\"F1-score: {100 * f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedna metryka rośnie, druga maleje - tak też się może zdarzyć. Takie sytuacje są zawsze ciekawe, bo pokazują różne aspekty tego, jak radzi sobie nasz klasyfikator. F1-score łączy precyzję i czułość, więc warto przeanalizować to głębiej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "  Precision: 57.14%\n",
      "  Recall: 6.45%\n",
      "\n",
      "RF with cost-sensitive learning\n",
      "  Precision: 72.22%\n",
      "  Recall: 10.48%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"RF\")\n",
    "rf_precision = precision_score(y_test, clf_rf.predict(X_test))\n",
    "rf_recall = recall_score(y_test, clf_rf.predict(X_test))\n",
    "print(f\"  Precision: {100 * rf_precision:.2f}%\")\n",
    "print(f\"  Recall: {100 * rf_recall:.2f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"RF with cost-sensitive learning\")\n",
    "rf_csl_precision = precision_score(y_test, clf_rf_csl.predict(X_test))\n",
    "rf_csl_recall = recall_score(y_test, clf_rf_csl.predict(X_test))\n",
    "print(f\"  Precision: {100 * rf_csl_precision:.2f}%\")\n",
    "print(f\"  Recall: {100 * rf_csl_recall:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z cost-sensitive learningiem predykcje prawdopodobieństwa co prawda są lepsze (bo mamy wyższy AUROC), ale i precyzja, i czułość spadły. No i w obu przypadkach mamy naprawdę niski recall!\n",
    "\n",
    "Coś trzeba z tym zrobić. Skoro F1-score to metryka binarna, to najłatwiej zmienić próg klasy pozytywnej, czyli zrobić threshold tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2 (1.5 punktu)**\n",
    "\n",
    "Zaimplementuj threshold tuning z pomocą walidacji skrośnej. Skorzystaj z funkcji `thresholded_f1_score()`, która jest gotową metryką, obliczającą F1-score dla podanych prawdopodobieństw klasy pozytywnej i progu klasyfikacji.\n",
    "\n",
    "1. Stwórz listę progów [0.1, 0.15, 0.2, .., 0.5]\n",
    "2. Dla każdego progu stwórz nowy obiekt metryki z pomocą funkcji `make_scorer()`. Pamiętaj, że większa wartość jest lepsza i potrzebujemy prawdopodobieństw. Trzeba też podać wartość dla naszego progu (`threshold`) z pomocą `**kwargs`.\n",
    "3. Oblicz wyniki walidacji skrośnej z pomocą funkcji `cross_val_score` dla Random Forest z cost-sensitive tuning. Wykorzystaj 5-fold CV. Funkcja ta zwraca wyniki dla wszystkich foldów - oblicz średni wynik.\n",
    "4. Zwizualizuj na wykresie wyniki F1-score dla poszczególnych progów. Pamiętaj o opisaniu osi i tytule wykresu.\n",
    "5. Dla optymalnego progu oblicz i wypisz F1-score, precision i recall. Próg, dla którego osiągnięto najwyższy F1-score, można łatwo wyciągnąć z pomocą `np.argmax()`.\n",
    "6. Skomentuj zmianę w precision i recall. Czy twoim zdaniem warto dokonać takiej zmiany w przypadku tego zbioru, tj. przewidywania, czy spółka zbankrutuje?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholded_f1_score(y_true, y_score, threshold: float, **kwargs) -> float:\n",
    "    y_pred = y_score >= threshold\n",
    "    return f1_score(y_true, y_pred, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "thresholds = np.arange(0.1, 0.51, 0.05)\n",
    "f1_scores = []\n",
    "clf_rf = RandomForestClassifier(class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "for threshold in thresholds:\n",
    "    scorer = make_scorer(thresholded_f1_score, \n",
    "                         threshold=threshold,\n",
    "                         response_method=\"predict_proba\")\n",
    "    \n",
    "    mean = np.mean(cross_val_score(estimator=clf_rf, \n",
    "                                   X=X_train, \n",
    "                                   y=y_train, \n",
    "                                   cv=5, \n",
    "                                   n_jobs=-1,\n",
    "                                   scoring=scorer))\n",
    "    f1_scores.append(mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_f1_tresh(f1_scores, thresholds):\n",
    "    plt.plot(thresholds, f1_scores)\n",
    "    plt.xlabel(\"Treshold\")\n",
    "    plt.ylabel(\"f1_score\")\n",
    "    \n",
    "visualize_f1_tresh(f1_scores, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal threshold: 0.15\n",
      "  F1-score: 42.31%\n",
      "  Precision: 40.44%\n",
      "  Recall: 44.35%\n"
     ]
    }
   ],
   "source": [
    "optimal_thresh_idx = np.argmax(f1_scores)\n",
    "optimal_thresh = thresholds[optimal_thresh_idx]\n",
    "y_pred = clf_rf.predict_proba(X_test)[:,1] >= optimal_thresh\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rf_csl_precision = precision_score(y_test, y_pred)\n",
    "rf_csl_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"optimal threshold: {optimal_thresh:.2f}\")\n",
    "print(f\"  F1-score: {100 * f1:.2f}%\")\n",
    "print(f\"  Precision: {100 * rf_csl_precision:.2f}%\")\n",
    "print(f\"  Recall: {100 * rf_csl_recall:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// KOMENTARZ\n",
    "\n",
    "Wydaje się że jednak pomimo lepszego wyniku f1 to zmiana w gorszą stronę. Recall jest tutaj ważniejsze, ponieważ lepiej wyciągnąć pieniądze z firmy która nie upadnie ale wyglądała jakby miała paść, niż nie wyciągnąć z tej która zbankrutuje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling, oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Być może klasa większościowa, której jest 95%, jest mocno zaszumiona i są tam przykłady, które warto byłoby usunąć. Czemu tak może być?\n",
    "\n",
    "Pamiętajmy, że klasa pozytywna to spółki, które zbankrutują w ciągu najbliższych 3 lat. Przy granicy decyzyjnej w klasie dominującej mogą być na przykład startupy o dużym ryzyku, które nie zbankrutowały, ale było to kwestią dobrej koniunktury i szczęśliwego trafu tych spółek. Równie dobrze mogłyby upaść przez niskie zasoby twarde czy rosnące koszty. Można je potraktować jak mało miarodajny szum, który tylko z przyczyn dość losowych nie stał się klasą pozytywną (tj. spółkami, które zamknęły działalność).\n",
    "\n",
    "Dla uproszczenia w tym i dalszych zadaniach skorzystamy z funkcji `assess_rf_performance()`, żeby łatwo sprawdzać AUROC i F1-score klasyfikatorów.\n",
    "\n",
    "Najpierw zastosujemy algorytm Edited Nearest Neighbors (ENN) z domyślnymi parametrami: \n",
    "- `k=3`\n",
    "- `kind_sel=\"all\"` (wszyscy sąsiedzi muszą być z klasy dominującej, aby punkt pozostał w zbiorze)\n",
    "\n",
    "Biblioteka imbalanced-learn opiera się o metodę `.fit_resample()`, która zwraca zmodyfikowany zbiór uczący (z usuniętymi/dodatkowymi próbkami). Implementuje także zmodyfikowany `Pipeline`, bo ten domyślny ze Scikit-learn nie wspierałby takiej metody. Warto pamiętać o tym, żeby tworzyć nowe zmienne dla zmodyfikowanych zbiorów, bo inaczej trzeba by wykonywać duże części notebooka na nowo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_rf_performance(estimator: RandomForestClassifier, X_test, y_test) -> None:\n",
    "    y_score = estimator.predict_proba(X_test)[:, 1]\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    auroc = roc_auc_score(y_test, y_score)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "    print(f\"F1-score: {100 * f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before ENN: 7877\n",
      "Samples after ENN: 6979\n",
      "AUROC: 85.25%\n",
      "F1-score: 14.49%\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "\n",
    "enn = EditedNearestNeighbours()\n",
    "print(f\"Samples before ENN: {len(X_train)}\")\n",
    "X_train_enn, y_train_enn = enn.fit_resample(X_train, y_train)\n",
    "print(f\"Samples after ENN: {len(X_train_enn)}\")\n",
    "\n",
    "clf_rf_csl = RandomForestClassifier(class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "clf_rf_csl.fit(X_train_enn, y_train_enn)\n",
    "\n",
    "assess_rf_performance(clf_rf_csl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wcześniej AUROC wynosiło 89.30%, a F1-score 28.00%. Mamy spadek obu metryk - niedobrze! Usunęliśmy jednak około 10% zbioru, może to za dużo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3 (1.5 punktu)**\n",
    "\n",
    "1. Dokonaj tuningu hiperparametrów ENN:\n",
    "   - stwórz siatkę hiperparametrów: \n",
    "     - liczba sąsiadów: `[1, 3, 5]`\n",
    "     - tryb wyboru punktów: `[\"all\", \"mode\"]`\n",
    "   - przed użyciem `GridSearchCV` stwórz pipeline (ten z biblioteki imbalanced-learn), łączący ENN i Random Forest\n",
    "   - wybierz klasyfikator o najwyższym AUROC\n",
    "   - wykorzystaj 10-fold CV - przy zbiorach niezbalansowanych często daje to dokładniejsze oszacowanie\n",
    "   - pamiętaj, żeby podać, którego elementu pipeline'u dotyczą hiperparametry w siatce (np. `enn__n_neighbors`)\n",
    "2. Wypisz znalezione optymalne wartości hiperparametrów. Sprawdź wyniki na zbiorze testowym.\n",
    "3. Czy usuwamy punkty agresywniej, czy bardziej konwerwatywnie? Zweryfikuj swoją intuicję, sprawdzając liczność zbioru przed i po zastosowaniu ENN z optymalnymi hiperparametrami.\n",
    "4. Czy undersampling ostatecznie poprawił wynik? Czy twoim zdaniem warto tu zastosować taką technikę?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;enn&#x27;, EditedNearestNeighbours()),\n",
       "                                       (&#x27;clf_rf&#x27;, RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf_rf__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;clf_rf__n_jobs&#x27;: [-1], &#x27;clf_rf__random_state&#x27;: [0],\n",
       "                         &#x27;enn__kind_sel&#x27;: [&#x27;all&#x27;, &#x27;mode&#x27;],\n",
       "                         &#x27;enn__n_neighbors&#x27;: [1, 3, 5]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;enn&#x27;, EditedNearestNeighbours()),\n",
       "                                       (&#x27;clf_rf&#x27;, RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf_rf__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;clf_rf__n_jobs&#x27;: [-1], &#x27;clf_rf__random_state&#x27;: [0],\n",
       "                         &#x27;enn__kind_sel&#x27;: [&#x27;all&#x27;, &#x27;mode&#x27;],\n",
       "                         &#x27;enn__n_neighbors&#x27;: [1, 3, 5]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;enn&#x27;, EditedNearestNeighbours()),\n",
       "                (&#x27;clf_rf&#x27;, RandomForestClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">EditedNearestNeighbours</label><div class=\"sk-toggleable__content fitted\"><pre>EditedNearestNeighbours()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('enn', EditedNearestNeighbours()),\n",
       "                                       ('clf_rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf_rf__class_weight': ['balanced'],\n",
       "                         'clf_rf__n_jobs': [-1], 'clf_rf__random_state': [0],\n",
       "                         'enn__kind_sel': ['all', 'mode'],\n",
       "                         'enn__n_neighbors': [1, 3, 5]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([\n",
    "    (\"enn\", EditedNearestNeighbours()),\n",
    "    (\"clf_rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"enn__n_neighbors\" : [1, 3, 5],\n",
    "    \"enn__kind_sel\" : [\"all\", \"mode\"],\n",
    "    \"clf_rf__class_weight\" : [\"balanced\"],\n",
    "    \"clf_rf__random_state\" : [0],\n",
    "    \"clf_rf__n_jobs\" : [-1]\n",
    "    }\n",
    "\n",
    "clf_grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    scoring=\"roc_auc\",\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "clf_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf_rf__class_weight': 'balanced', 'clf_rf__n_jobs': -1, 'clf_rf__random_state': 0, 'enn__kind_sel': 'mode', 'enn__n_neighbors': 3}\n",
      "  F1-score: 38.52%\n",
      "  Precision: 39.17%\n",
      "  Recall: 37.90%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_grid.predict_proba(X_test)[:,1] >= optimal_thresh\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rf_csl_precision = precision_score(y_test, y_pred)\n",
    "rf_csl_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", clf_grid.best_params_)\n",
    "print(f\"  F1-score: {100 * f1:.2f}%\")\n",
    "print(f\"  Precision: {100 * rf_csl_precision:.2f}%\")\n",
    "print(f\"  Recall: {100 * rf_csl_recall:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before ENN: 7877\n",
      "Samples after ENN: 7810\n"
     ]
    }
   ],
   "source": [
    "enn_best = EditedNearestNeighbours(kind_sel='mode',\n",
    "                                   n_neighbors=3)\n",
    "X_after_enn, y_after_enn = enn_best.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Samples before ENN: {len(X_train)}\")\n",
    "print(f\"Samples after ENN: {len(X_after_enn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//  KOMENTARZ\n",
    "\n",
    "Niestety undersampling nie sprawdził się. Wartości się pogoszyły. 'mod' jako strategia usuwania wskazuje że punkt wcale nie musiał mieć wszystkich sąsiadów takich samych jak on, więc do przewidzenia był fakt iż będzie łagodniejsze usuwanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Być może oversampling da nam większe korzyści, w końcu klasy pozytywnej jest naprawdę mało. Wypróbujmy najpierw SMOTE z domyślnymi hiperparametrami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before SMOTE: 7877\n",
      "Samples after SMOTE: 15012\n",
      "AUROC: 84.99%\n",
      "F1-score: 34.55%\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "print(f\"Samples before SMOTE: {len(X_train)}\")\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Samples after SMOTE: {len(X_train_smote)}\")\n",
    "\n",
    "clf_rf_csl = RandomForestClassifier(class_weight=\"balanced\", random_state=0, n_jobs=-1)\n",
    "clf_rf_csl.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "assess_rf_performance(clf_rf_csl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest definitywnie lepiej! Liczba przykładów z klasy pozytywnej wzrosła bardzo mocno, ale dzięki skalowalności lasu losowego nie jest to drastycznie odczuwalne. Za to F1-score bardzo wzrósł, bo zwiększyliśmy znacząco wagę klasy mniejszościowej, i to zagęszczając ją w przestrzeni zbioru danych. Dzięki temu i FP, i FN spadną.\n",
    "\n",
    "Imbalanced-learn domyślnie generuje tyle klasy mniejszościowej, żeby było jej tyle samo, co dominującej. Prawie zawsze powoduje to overfitting - zweryfikujmy to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "AUROC: 100.00%\n",
      "F1-score: 100.00%\n",
      "\n",
      "Test metrics\n",
      "AUROC: 84.99%\n",
      "F1-score: 34.55%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train metrics\")\n",
    "assess_rf_performance(clf_rf_csl, X_train, y_train)\n",
    "print()\n",
    "print(\"Test metrics\")\n",
    "assess_rf_performance(clf_rf_csl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest to wręcz tragiczny overfitting! Definitywnie trzeba tutaj tuningu. Imbalanced-learn pozwala na to poprzez parametr `sampling_strategy`. Jeżeli jest to liczba, to oznacza stosunek liczby przykładów klasy mniejszościowej do liczby przykładów klasy większościowej po oversamplingu.\n",
    "\n",
    "Przykładowo, domyślne ustawienia odpowiadają `sampling_strategy=1`, czyli:\n",
    "\n",
    "$$\\large\n",
    "\\frac{n_{minority}}{n_{majority}} = 1 \\longrightarrow n_{minority} = n_{majority}\n",
    "$$\n",
    "\n",
    "Żeby zmniejszyć overfitting, trzeba generować mniej klasy pozytywnej, czyli zmniejszyć tę proporcję. Dodatkowo możemy zmienić wartość najbliższych sąsiadów - mniejsza liczba będzie skutkować generacją bardziej wiernych lokalnie próbek, a większa zwiększy różnorodność."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4 (2 punkty)**\n",
    "\n",
    "Ze względu na koszt obliczeniowy połączenia 10-fold CV i metod opartych o sąsiedztwo można wykonać **step-wise tuning**, w którym robimy walidację skrośną po kolei dla parametrów, zamiast sprawdzać wszystkie kombinacje po kolei. Nie daje to gwarancji optymalności, ale typowo działa bardzo dobrze, a przy tym jest dużo szybsze. Jest to typowo stosowane w boostingu, który ma bardzo dużo hiperparametrów, ale także przy innych kosztownych algorytmach. Dobrze opisuje to [ten artykuł](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258).\n",
    "\n",
    "Dokonaj po kolei tuningu:\n",
    "- liczby sąsiadów w SMOTE w zakresie `[1, 2, 3, 4, 5]`\n",
    "- ilości klasy pozytywnej w zakresie od 0.25 do 1 z krokiem 0.25 (może się przydać `np.linspace()` albo  `np.arange()`)\n",
    "\n",
    "Zwróć uwagę na:\n",
    "- 10-fold CV\n",
    "- ustawienie `random_state=0`\n",
    "- przyda się ustawić `verbose=4`, żeby mieć logi z wykonania, bo będzie się to chwilę liczyć\n",
    "\n",
    "Sprawdź wyniki obu pipeline'ów (z osobna) na zbiorze treningowym oraz testowym. Wytrenuj także łączny pipeline, wykorzystując oba znalezione parametry naraz, i sprawdź jego wyniki.\n",
    "\n",
    "Pamiętaj, że nie trzeba przetrenowywać klasyfikatorów na finalnych hiperparametrach - obiekt `GridSearchCV` też ma metodę `.predict()`, w któryj pod spodem użyje modelu z najlepszymi znalezionymi wartościami hiperparametrów.\n",
    "\n",
    "Skomentuj:\n",
    "- czy wynik się poprawił?\n",
    "- czy zmniejszono lub wyeliminowano overfitting w którymś przypadku?\n",
    "- czy warto było tune'ować oba parametry?\n",
    "- czy połączenie parametrów poprawiło wynik?\n",
    "\n",
    "Oszacuj, ile wolniej wykonywałby się grid search na pełnej, kwadratowej siatce hiperparametrów. Oblicz liczbę modeli, którą trzeba by wytrenować w obu przypadkach (step-wise oraz na pełnej siatce) przy 10-fold CV, i przyjmij stały średni czas na jeden fold według logów z treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.863 total time=   3.1s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.834 total time=   1.1s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.799 total time=   1.0s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.897 total time=   1.0s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.840 total time=   1.0s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.880 total time=   1.0s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.873 total time=   1.0s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.883 total time=   1.0s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.821 total time=   1.0s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=1, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.769 total time=   1.0s\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.855 total time=   1.0s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.833 total time=   1.0s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.819 total time=   1.0s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.877 total time=   1.0s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.838 total time=   1.0s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.865 total time=   1.0s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.882 total time=   1.0s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.870 total time=   1.0s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.838 total time=   1.0s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.738 total time=   1.0s\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.868 total time=   1.0s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.819 total time=   1.0s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.783 total time=   1.0s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.886 total time=   1.0s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.836 total time=   1.0s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.858 total time=   1.0s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.887 total time=   1.0s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.879 total time=   1.0s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.845 total time=   1.0s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=3, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.757 total time=   1.0s\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.862 total time=   1.0s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.824 total time=   1.0s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.775 total time=   1.0s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.884 total time=   1.0s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.844 total time=   1.0s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.863 total time=   1.0s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.887 total time=   1.0s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.879 total time=   1.0s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.825 total time=   1.0s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=4, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.746 total time=   1.0s\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.850 total time=   1.0s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.831 total time=   1.0s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.776 total time=   1.0s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.898 total time=   1.0s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.830 total time=   1.0s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.879 total time=   1.0s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.876 total time=   1.0s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.880 total time=   1.0s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.825 total time=   1.0s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=5, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.739 total time=   1.1s\n",
      "{'clf__class_weight': 'balanced', 'clf__n_jobs': -1, 'clf__random_state': 0, 'smote__k_neighbors': 1, 'smote__random_state': 0, 'smote__sampling_strategy': 0.25}\n",
      "TIME: 0.9718718449274699 min\n",
      "Train metrics\n",
      "AUROC: 100.00%\n",
      "F1-score: 100.00%\n",
      "\n",
      "Test metrics\n",
      "AUROC: 85.22%\n",
      "F1-score: 28.21%\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.855 total time=   1.0s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.833 total time=   1.0s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.819 total time=   1.0s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.877 total time=   1.0s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.838 total time=   1.0s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.865 total time=   1.0s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.882 total time=   1.0s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.870 total time=   1.0s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.838 total time=   1.0s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.25;, score=0.738 total time=   1.0s\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.852 total time=   1.2s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.819 total time=   1.3s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.779 total time=   1.2s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.886 total time=   1.2s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.847 total time=   1.2s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.861 total time=   1.2s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.886 total time=   1.2s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.870 total time=   1.2s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.825 total time=   1.9s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.5;, score=0.754 total time=   1.4s\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.857 total time=   1.6s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.802 total time=   1.7s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.775 total time=   1.5s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.885 total time=   1.5s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.806 total time=   1.5s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.856 total time=   1.5s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.884 total time=   1.4s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.874 total time=   1.5s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.811 total time=   1.4s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=0.75;, score=0.759 total time=   1.4s\n",
      "[CV 1/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.846 total time=   1.6s\n",
      "[CV 2/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.808 total time=   1.6s\n",
      "[CV 3/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.801 total time=   1.6s\n",
      "[CV 4/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.878 total time=   1.6s\n",
      "[CV 5/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.829 total time=   1.6s\n",
      "[CV 6/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.865 total time=   1.6s\n",
      "[CV 7/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.880 total time=   1.6s\n",
      "[CV 8/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.873 total time=   1.6s\n",
      "[CV 9/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.824 total time=   1.6s\n",
      "[CV 10/10] END clf__class_weight=balanced, clf__n_jobs=-1, clf__random_state=0, smote__k_neighbors=2, smote__random_state=0, smote__sampling_strategy=1.0;, score=0.723 total time=   1.6s\n",
      "{'clf__class_weight': 'balanced', 'clf__n_jobs': -1, 'clf__random_state': 0, 'smote__k_neighbors': 2, 'smote__random_state': 0, 'smote__sampling_strategy': 0.25}\n",
      "TIME: 0.9877984722455343 min\n",
      "Train metrics\n",
      "AUROC: 100.00%\n",
      "F1-score: 100.00%\n",
      "\n",
      "Test metrics\n",
      "AUROC: 84.48%\n",
      "F1-score: 28.93%\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "pipeline = Pipeline([\n",
    "    (\"smote\", SMOTE()),\n",
    "    (\"clf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"smote__k_neighbors\" : list(range(1,6)),\n",
    "    \"smote__sampling_strategy\" : [0.25],\n",
    "    \"smote__random_state\" : [0],\n",
    "    \"clf__class_weight\" : [\"balanced\"],\n",
    "    \"clf__random_state\" : [0],\n",
    "    \"clf__n_jobs\" : [-1]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"estimator\": pipeline,\n",
    "    \"scoring\": \"roc_auc\",\n",
    "    \"param_grid\": param_grid,\n",
    "    \"verbose\": 4,\n",
    "    \"cv\": 10\n",
    "}\n",
    "def train_grid(params):\n",
    "    clf_grid = GridSearchCV(**params)\n",
    "    t = time()\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    t2 = time()\n",
    "    print(clf_grid.best_params_)\n",
    "    print(f\"TIME: {(t2 - t)/60} min\")\n",
    "    print(\"Train metrics\")\n",
    "    assess_rf_performance(clf_grid, X_train, y_train)\n",
    "    print()\n",
    "    print(\"Test metrics\")\n",
    "    assess_rf_performance(clf_grid, X_test, y_test)\n",
    "\n",
    "train_grid(params)\n",
    "\n",
    "param_grid[\"smote__k_neighbors\"] = [2]\n",
    "param_grid[ \"smote__sampling_strategy\"] = np.arange(0.25, 1.01, 0.25)\n",
    "\n",
    "train_grid(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 85.22%\n",
      "F1-score: 28.21%\n"
     ]
    }
   ],
   "source": [
    "smote_best = {\n",
    "    \"k_neighbors\" : 1,\n",
    "    \"sampling_strategy\" : 0.25,\n",
    "    \"random_state\" : 0,\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"smote\", SMOTE(**smote_best)),\n",
    "    (\"clf\", RandomForestClassifier(class_weight=\"balanced\", \n",
    "                                   random_state=0, \n",
    "                                   n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "assess_rf_performance(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// KOMENTARZ\n",
    "\n",
    "Wynik AUROC się lekko poprawił, natomiast f1 zmalało. Dalej występuje mocny overfitting bez względu na optymalizowany parametr. Przypadkiem okazało się że tuning drugiego parametru był nie dokońca potrzebny, gdyż ustawiłem `sampling_strategy=0.25` jako domyślne w pierwszym tuningu sąsiadów. Połączenie parametrów nie poprawiło zatem wyniku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Obliczenia:\n",
    "\n",
    "Biorąc pod uwagę, że dla różnych wartości sąsiadów wychodził bardzo podobny czas (1s)\n",
    "natomiast przy zmianie strategii zwiększał się czas (0.25~1s, 0.5~1.2s, 0.75~1.5s, 1~1.6s) Można założyć, że mamy w takim wypadku różnicę czasu tylko dla strategii.\n",
    "\n",
    "Dla każdej wartości sąsiadów (5) było 10 foldów, tak więc dla 4 różnych czasów mamy:\n",
    "\n",
    "$50 * 1 + ... + 50 * 1.6 = $\n",
    "\n",
    "$ 50 * (1 + 1.2 + 1.5 + 1.6) =  $\n",
    "\n",
    "$ 5 * 10 * (1 + 1.2 + 1.5 + 1.6) = $\n",
    "\n",
    "$ 5 $ * czas drugiego tuningu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnią rzeczą, którą możemy tu zrobić, jest połączenie naszych technik. Imbalanced-learn implementuje wygodne połączenie oversamplingu z undersamplingu w module `combine`, np. klasą `SMOTEENN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 99.77%\n",
      "F1-score: 61.33%\n",
      "AUROC: 82.57%\n",
      "F1-score: 30.03%\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "\n",
    "smote_enn_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"smoteenn\", SMOTEENN(random_state=0)),\n",
    "        (\n",
    "            \"rf\",\n",
    "            RandomForestClassifier(class_weight=\"balanced\", random_state=0, n_jobs=-1),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "smote_enn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "assess_rf_performance(smote_enn_pipeline, X_train, y_train)\n",
    "assess_rf_performance(smote_enn_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy domyślnych hiperparametrach, połączenie SMOTE i ENN daje gorsze wyniki niż sam SMOTE. Może jednak to kwestia tuningu?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5 (0.5 punktu)**\n",
    "\n",
    "Wytrenuj SMOTEENN, wykorzystując optymalne hiperparametry znalezione podczas tuningu ENN oraz SMOTE. Sprawdź wyniki na zbiorze testowym.\n",
    "\n",
    "Porównaj wyniki ENN, SMOTE oraz ich połączenia. Które rozwiązanie wybrałbyś w praktyce i dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind_sel': 'mode', 'n_neighbors': 3}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enn_best_params = {'kind_sel': 'mode', 'n_neighbors': 3}\n",
    "smote_best_params = {'k_neighbors': 1, 'sampling_strategy': 0.25, 'random_state': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEENN\n",
      "AUROC: 84.51%\n",
      "F1-score: 30.49%\n",
      "Precision: 16.05%\n",
      "Recall: 73.39%\n",
      "\n",
      "EditedNearestNeighbours\n",
      "AUROC: 85.28%\n",
      "F1-score: 17.27%\n",
      "Precision: 39.17%\n",
      "Recall: 37.90%\n",
      "\n",
      "SMOTE\n",
      "AUROC: 85.22%\n",
      "F1-score: 28.21%\n",
      "Precision: 18.80%\n",
      "Recall: 62.90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enn_best = EditedNearestNeighbours(**enn_best_params)\n",
    "smote_best = SMOTE(**smote_best_params)\n",
    "smoteenn_best = SMOTEENN(smote=smote_best,\n",
    "                         enn=enn_best)\n",
    "\n",
    "MODS = [smoteenn_best, enn_best, smote_best]\n",
    "\n",
    "for modifier in MODS:\n",
    "    pipeline = Pipeline([\n",
    "    (\"mod\", modifier),\n",
    "    (\"clf\", RandomForestClassifier(class_weight=\"balanced\", \n",
    "                                   random_state=0, \n",
    "                                   n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(modifier.__class__.__name__)\n",
    "    assess_rf_performance(pipeline, X_test, y_test)\n",
    "\n",
    "    y_pred = pipeline.predict_proba(X_test)[:,1] >= optimal_thresh\n",
    "    rf_csl_precision = precision_score(y_test, y_pred)\n",
    "    rf_csl_recall = recall_score(y_test, y_pred)\n",
    "    print(f\"Precision: {100 * rf_csl_precision:.2f}%\")\n",
    "    print(f\"Recall: {100 * rf_csl_recall:.2f}%\")\n",
    "\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//KOMENTARZ\n",
    "\n",
    "Do tego konkretnego zastosowania dalej bym się upierał że Recall jest najważniejszy, więc wydaje mi się że SMOTEENN daje sobie już dobrze radę, mimo iż precyzja lekko kuleje, szczególnie względem dwóch składowych na nią modyfikatorów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja ekstremalnie niezbalansowana i anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako nasz drugi zbiór wykorzystamy [Credit Card Fraud Detection dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud). Został on stworzony przez naukowców z Université Libre de Bruxelles we współpracy z firmą Wordline, obsługującą transakcje finansowe. Jest to największa europejska firma tego typu, i jedna z największych na świecie. Na potrzeby tego datasetu udostępniła transakcje z Europy z września 2013 roku.\n",
    "\n",
    "Jest to ponad 284 tysiące transakcji, z czego zaledwie 492 to transakcje będące wynikiem przestępstwa (fraud transaction). Klasa pozytywna to zatem około 0.172% danych, co wymaga specjalnych algorytmów i metryk. Cechy w zbiorze zostały zanonimizowane za pomocą transformacji PCA, dzięki czemu można było publicznie udostępnić taki zbiór. Jedynie publicznie znane cechy to \"Time\" i \"Amount\". Wszystkie cechy są numeryczne i nie ma wartości brakujących, a dane są najwyższej możliwej jakości (generowane automatycznie, a fraud jest bardzo dokładnie sprawdzany jako przestępstwa), więc jest doskonały do uczenia maszynowego.\n",
    "\n",
    "Warto pamiętać, że chociaż fraud to tak mało danych, to każdy jeden przypadek to bardzo ciężkie przestępstwo, często mogące zrujnować komuś życie, więc wykrycie możliwie jak największej liczby z nich obowiązkiem prawnym firm finansowych. Z tego względu algorytmy stanowią tutaj część systemu, flagujące transakcje jako podejrzane według prawdopodobieństwa. Później następuje weryfikacja ręczna w takich wypadkach.\n",
    "\n",
    "Ze względu na powyższe cechy zbioru, autorzy proponują metrykę **Area Under Precision-Recall Curve (AUPRC)**. Trzeba pamiętać, żeby uważać przy łączeniu jej z under- i oversamplingiem, bo zmieniają one proporcję klasy pozytywnej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze względu na bardzo duży rozmiar zbioru najpierw go zmniejszymy, żeby wszystko liczyło się w rozsądnym czasie. Naruszymy przy tym balans klas i zwiększymy stosunek outlierów, ale ze względów czysto praktycznych jesteśmy do tego zmuszeni. Dokonamy takiego losowego undersamplingu, żeby zostało 50 tysięcy próbek z klasy negatywnej i wszystkie z klasy pozytywnej.\n",
    "\n",
    "W praktyce też tak się czasem robi - na nic nam potężna ilość danych, jeżeli nie jesteśmy w stanie nic na tym policzyć. Ostatecznie fraud transaction stanowią dalej niecały 1% naszych danych, więc zbiór dalej jest ekstremalnie niezbalansowany i przybliżenie prawdziwych danych jest dobre.\n",
    "\n",
    "Ma to też tę zaletę, że zwalcza zjawisko nazywane **swamping**. Występuje ono w anomaly detection, gdy mamy totalnie za dużo klasy dominującej i nachodzi ona na chmurę punktów z klasy mniejszościowej (anomalii), \"zalewając\" ją. Powoduje to często FP, kiedy te przykłady z klasy dominującej zostają uznane za pozytywne.\n",
    "\n",
    "Standaryzujemy też dane, bo skorzystamy z metod opartych o najbliższych sąsiadów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"credit_card_fraud_data.parquet\")\n",
    "# df = df.drop(columns=\"Time\") # Nie wiem dlaczego, ale już w df nie ma takiej kolumny, więc omijam\n",
    "y = df.pop(\"Class\")\n",
    "\n",
    "sampling_strategy = {0: 50000, 1: (y == 1).sum()}\n",
    "\n",
    "random_under_sampler = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "df, y = random_under_sampler.fit_resample(df, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud class after resampling: 0.97% of the dataset\n"
     ]
    }
   ],
   "source": [
    "y_pos_count = (y == 1).sum()\n",
    "y_pos_perc = y_pos_count / len(y)\n",
    "\n",
    "print(f\"Fraud class after resampling: {100 * y_pos_perc:.2f}% of the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy po kolei dwóch algorytmów nienadzorowanego outlier detection:\n",
    "- kNN\n",
    "- Isolation Forest\n",
    "\n",
    "Jako wartość parametru `contamination`, czyli oczekiwanej proporcji outlierów, warto zacząć po prostu od ułamka anomalii w zbiorze treningowym, jeżeli jest ona znana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "def assess_anomaly_detection_model(estimator, X_test, y_test) -> None:\n",
    "    y_pred_score = estimator.predict_proba(X_test)\n",
    "\n",
    "    # in PyOD, .predict_proba() sometimes returns probability distribution,\n",
    "    # and sometimes it returns only probability of being anomaly\n",
    "    if len(y_pred_score.shape) > 1:\n",
    "        y_pred_score = y_pred_score[:, 1]\n",
    "\n",
    "    auprc = average_precision_score(y_test, y_pred_score)\n",
    "    print(f\"AUPRC: {100 * auprc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN metrics\n",
      "AUPRC: 13.99%\n",
      "\n",
      "Isolation Forest metrics\n",
      "AUPRC: 41.19%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "\n",
    "contamination = (y == 1).sum() / len(y)\n",
    "\n",
    "knn = KNN(contamination=contamination, n_jobs=-1)\n",
    "knn.fit(X_train)\n",
    "print(\"kNN metrics\")\n",
    "assess_anomaly_detection_model(knn, X_test, y_test)\n",
    "print()\n",
    "\n",
    "iforest = IForest(contamination=contamination, behaviour=\"new\", random_state=0, n_jobs=-1)\n",
    "iforest.fit(X_train)\n",
    "print(\"Isolation Forest metrics\")\n",
    "assess_anomaly_detection_model(iforest, X_test, y_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN wykazuje na pewno potencjał (pamiętajmy, że AUPRC ma typowo bardzo niskie wartości!), ale nasz zbiór jest dość duży, więc czuć wolniejsze tempo tej metody, a niestety PyOD nie współgra dobrze z PyNNDescent, żeby go przyspieszyć z użyciem ANN. Dlatego skupimy się teraz na Isolation Forest.\n",
    "\n",
    "Jego najważniejsze hiperparametry to:\n",
    "- `n_estimators` - liczba drzew, typowo ok. 500 jest już osiągana asymptota wyniku\n",
    "- `max_samples` - wielkość próbki per drzewo, domyślnie 256, ale nieco większa może pomóc, jeżeli mamy naprawdę masywny zbiór\n",
    "\n",
    "Typowo `contamination` niewiele zmienia w przypadku tego algorytmu, kiedy używamy metryki opartej o prawdopodobieństwa, takiej jak AUPRC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (1.5 punktu)**\n",
    "\n",
    "1. Dokonaj tuningu hiperarametrów po kolei (step-wise) za pomocą walidacji skrośnej:\n",
    "   - najpierw `n_estimators`, wartości `[100, 200, 300, 400, 500]`\n",
    "   - później `max_samples`,  wartości `[100, 200, 256, 300, 400, 500]`\n",
    "   - wykorzystaj wartość `contamination` obliczoną wcześniej\n",
    "   - użyj `random_state=0` i `n_jobs=-1` dla obiektu `IForest`\n",
    "   - użyj 5-krotnej walidacji skrośnej, optymalizując `\"average_precision\"` (AUPRC)\n",
    "2. Wypisz znalezione optymalne wartości parametrów.\n",
    "3. Wytrenuj Isolation Forest z wartościami obu parametrów. Sprawdź wynik na zbiorze testowym.\n",
    "4. Skomentuj, czy udało się poprawić wynik. Czy twoim zdaniem było warto dokonać tuningu obu hiperparamametrów, czy wystarczyłby jeden z nich?\n",
    "\n",
    "**Uwaga:** przez drobnego buga w połączeniu `pyod` i najnowszych wersji Scikit-learn trzeba użyć explicite funkcji obliczającej AUPRC, przygotowano ją poniżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def auprc(estimator, X, y):\n",
    "    return average_precision_score(y, estimator.predict_proba(X))\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\" : [100, 200, 300, 400, 500],\n",
    "    \"max_samples\" : [256],\n",
    "    \"random_state\" : [0],\n",
    "    \"contamination\" : [contamination],\n",
    "    \"n_jobs\" : [-1]\n",
    "}\n",
    "\n",
    "\n",
    "auprc = make_scorer(average_precision_score)\n",
    "\n",
    "params = {\n",
    "    \"estimator\": IForest(),\n",
    "    \"scoring\": auprc,\n",
    "    \"param_grid\": param_grid,\n",
    "    \"verbose\": 1,\n",
    "    \"cv\": 5\n",
    "}\n",
    "\n",
    "def train_grid(params, paramName=None):\n",
    "    clf_grid = GridSearchCV(**params)\n",
    "    t = time()\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    t2 = time()\n",
    "    if paramName:\n",
    "        print(f\"best {paramName}: {clf_grid.best_params_[paramName]}\")\n",
    "    print(f\"TIME: {(t2 - t)/60} min\")\n",
    "    print(\"Train metrics\")\n",
    "    assess_anomaly_detection_model(clf_grid, X_train, y_train)\n",
    "    print()\n",
    "    print(\"Test metrics\")\n",
    "    assess_anomaly_detection_model(clf_grid, X_test, y_test)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklern zapętlił się w logice, ponieważ uważał że nie powinno dawać się `y`, ale gdy go brakowało nie chciał działać, więc po prostu ustawiłem brak warningów na chwilę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"y should not be present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "best n_estimators: 500\n",
      "TIME: 0.6765214800834656 min\n",
      "Train metrics\n",
      "AUPRC: 51.07%\n",
      "\n",
      "Test metrics\n",
      "AUPRC: 44.38%\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "best max_samples: 300\n",
      "TIME: 0.6424947619438172 min\n",
      "Train metrics\n",
      "AUPRC: 50.36%\n",
      "\n",
      "Test metrics\n",
      "AUPRC: 42.88%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_grid(params, \"n_estimators\")\n",
    "param_grid[\"n_estimators\"] = [300]\n",
    "param_grid[\"max_samples\"] = [100, 200, 256, 300, 400, 500]\n",
    "train_grid(params, \"max_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"default\", message=\"y should not be present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 3.51%\n",
      "Recall: 92.68%\n",
      "AUPRC: 45.05%\n"
     ]
    }
   ],
   "source": [
    "params_iforest = {\n",
    "    \"n_estimators\" : 500,\n",
    "    \"max_samples\" : 300,\n",
    "    \"random_state\" : 0,\n",
    "    \"contamination\" : contamination,\n",
    "    \"n_jobs\" : -1\n",
    "}\n",
    "best_if = IForest(**params_iforest)\n",
    "best_if.fit(X_train)\n",
    "\n",
    "y_pred = best_if.predict_proba(X_test)[:,1] >= optimal_thresh\n",
    "rf_csl_precision = precision_score(y_test, y_pred)\n",
    "rf_csl_recall = recall_score(y_test, y_pred)\n",
    "print(f\"Precision: {100 * rf_csl_precision:.2f}%\")\n",
    "print(f\"Recall: {100 * rf_csl_recall:.2f}%\")\n",
    "assess_anomaly_detection_model(best_if, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// KOMENTARZ\n",
    "\n",
    "Wynik zadowalający, aczkolwiek jest lekka niepewność związana z ilością FP, która jest ogromna (nie można przesłuchiwać co drugiego klienta banku czy nie popełnił przypadkiem zbrodni na zakupie bułek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaprezentowane podejścia należały do **uczenia nienadzorowanego (unsupervised learning)**, gdyż te algorytmy nie potrzebowały klas dla przykładów ze zbioru treningowego. W szczególności Isolation Forest potrafi działać bardzo dobrze nawet wtedy, kiedy zbiór uczący nie zawiera żadnych anomalii. Wykorzystanie takich algorytmów jest zatem proste i tanie, a w szczególności można dla nich łatwo stworzyć potężne zbiory danych.\n",
    "\n",
    "Jeżeli mamy luksus posiadania pełnej informacji o klasach, możemy użyć algorytmów uczenia nadzorowanego (supervised learning). W szczególności można także połączyć te podejścia, co realizuje **uczenie pół-nadzorowane (semi-supervised learning)**, którego przedstawicielem jest XGBoost Outlier Detection (XGBOD). Polega on na obliczeniu anomaly scores dla próbek za pomocą algorytmów nienadzorowanych (np. kNN czy Isolation Forest) i doklejeniu ich jako dodatkowych cech do naszego zbioru treningowego. Można stosować jeden algorytm wielokrotnie, np. kNN dla wielu wartości k, bo wtedy XGBoost ma wiele nowych cech (dla różnych gęstości outlierów) i może je elastycznie łączyć.\n",
    "\n",
    "Tak naprawdę podejście to jest bardzo ogólne, i można by zastosować dowolne połączenia ekstrekcji dodatkowych cech anomalii i klasyfikatorów. XGBOD to po prostu pierwszy zaproponowany przykład takiego algorytmu i działa naprawdę dobrze.\n",
    "\n",
    "PyOD implementuje to w klasie `XGBOD`, która przyjmuje argument `estimator_list`. Jest to lista obiektów klas do nienadzorowanego outlier detection, np. `KNN` czy `IForest` (samych klas, przed treningiem przez `.fit()`). Sam trening i predykcja działa tak jak w przypadku poprzednich algorytmów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 7 (1.5 punktu)**\n",
    "\n",
    "1. Stwórz listę `estimator_list`, składającą się z:\n",
    "   - algorytmów `KNN` z `n_neighbors`: `[1, 3, 5, 10, 20, 30]`\n",
    "   - algorytmów `IForest` z `n_estimators`: `[50, 100, 200, 300]`\n",
    "   - pamiętaj o przekazaniu `n_jobs=-1` oraz `random_state=0` (w razie potrzeby) podczas tworzenia obiektów tych klas\n",
    "2. Wytrenuj algorytm `XGBOD`, pamiętaj o przekazaniu stworzonego `estimator_list` raz o ustawieniu `n_jobs=-1` i `random_state=0`.\n",
    "3. Dokonaj ewaluacji wyników na zbiorze testowym.\n",
    "4. Skomentuj:\n",
    "   - jak mają się do siebie wyniki podejścia nienadzorowanego i w pełni nadzorowanego?\n",
    "   - co uważasz o podejściu pół-nadzorowanym, w którym skorzystaliśmy z dodatkowych cech?\n",
    "   - czy twoim zdaniem finalna wartość metryki jest zadowalająca?\n",
    "   - czy trening subiektywnie trwał zauważalnie dłużej od tego dla algorytmów nienadzorowanych?\n",
    "   - czy twoim zdaniem warto ponieść wysiłek i koszty, pozwalające na użycie takiego algorytmu pół-nadzorowanego?\n",
    "\n",
    "**Uwaga:** może się to liczyć dość długo, rzędu kilku minut. Jeżeli będzie definitywnie zbyt długie, zmniejsz liczbę algorytmów KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "\n",
    "knn_list = [KNN(n_neighbors=i, n_jobs=-1) for i in [1, 3, 5, 10, 20, 30]]\n",
    "forest_list = [IForest(n_estimators=i, n_jobs=-1, random_state=0) for i in [50, 100, 200, 300]]\n",
    "estimator_list = knn_list + forest_list\n",
    "\n",
    "\n",
    "xgb_clf = XGBOD(\n",
    "            estimator_list=estimator_list,\n",
    "            n_jobs=-1,\n",
    "            random_state=0\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Install\\anaconda\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:04:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC: 86.43%\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(X_train, y_train)\n",
    "assess_anomaly_detection_model(xgb_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// KOMENTARZ\n",
    "- podejście w pełni nadzorowane wydawało się lekko lepsze wyniki niż nienadzorowane\n",
    "- pół-nadzorowane podejście wydaje się najlepszym pod względem wyników rozwiązaniem. Problemem jest jedynie czas który wymagał na predykcję, który ze względu na dużo odpaleń KNN i lasów był najdłuższy (większy niż wszystkie inne metody i ich trenowanie)\n",
    "- zawsze może być lepiej, natomiast względem początkowych wartości jest już dużo lepiej\n",
    "- trening wydawał się wcale nie dłuższy, oczywiście wymagał wytrenowania wielu modeli, ale względem czasu predykcji - znikomy\n",
    "- jeśli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie dodatkowe (3 punkty)\n",
    "\n",
    "W przypadku niektórych zbiorów danych anomalie mogą być zjawiskiem dość pozytywnym, tylko po prostu ekstremalnie rzadkim. Jest tak typowo w farmacji, gdzie molekuły będące potencjalnymi lekami są bardzo niewielkim ułamkiem zbiorów nawet wśród wstępnie typowanych, obiecujących substancji. Pierwszy etap projektowania nowych leków, tzw. high-throughput screening (HTS), polega na identyfikacji tego bardzo niewielkiego podzbioru spośród wielkich baz molekuł, w celu dalszego badania.\n",
    "\n",
    "Zbiór AID746, [dostępny na platformie Kaggle](https://www.kaggle.com/datasets/uciml/bioassay-datasets), dotyczy identyfikacji kinaz białkowych aktywowanych mitogenami ([Wikipedia](https://pl.wikipedia.org/wiki/Kinazy_aktywowane_mitogenami)). Są to enzymy regulujące odpowiedzi na sygnały docierające do komórki, regulujące wiele ciekawych funkcji. Mają potencjalne zastosowania m.in. w rozwoju metod chemoterapii, badaniu insulinoodporności czy rozwoju leków przeciwzapalnych ([Wikipedia](https://en.wikipedia.org/wiki/Mitogen-activated_protein_kinase#As_therapeutic_targets)).\n",
    "\n",
    "W tym zbiorze danych klasa substancji aktywnych stanowi 0.61% zbioru, spośród ok. 57 tysięcy substancji w zbiorze. Jest on już podzielony na część treningową i testową.\n",
    "\n",
    "Dokonaj klasyfikacji oraz tuningu hiperparametrów dla tego zbioru z pomocą:\n",
    "- kNN\n",
    "- Isolation Forest\n",
    "- XGBOD - tu warto zwrócić uwagę też na parametr `scale_pos_weight`, którego dla uproszczenia nie używaliśmy w ostatnim zadaniu\n",
    "\n",
    "Możesz spróbować także użyć undersamplingu, oversamplingu oraz ich połączenia.\n",
    "\n",
    "Jako metryki użyj AUPRC. Podaj także czułość (recall) finalnego algorytmu - w końcu na etapie początkowego filtrowania substancji chcemy na pewno mieć jak najmniej false negatives.\n",
    "\n",
    "Na podstawie wyników oceń, z jakim typem anomalii mamy tu do czynienia. Czy udało się uzyskać zadowalające w twojej ocenie wyniki?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data_AID/AID746red_train.csv')\n",
    "X_test = pd.read_csv('data_AID/AID746red_test.csv')\n",
    "y_train = X_train.pop(\"Outcome\")\n",
    "y_test = X_test.pop(\"Outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nieskończone :c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [117]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m param_grid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_grid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     35\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, \n\u001b[0;32m     36\u001b[0m                            param_grid, \n\u001b[0;32m     37\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m     38\u001b[0m                            scoring\u001b[38;5;241m=\u001b[39mauprc, \n\u001b[0;32m     39\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     40\u001b[0m                            verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m grid_search_results\u001b[38;5;241m.\u001b[39mappend(grid_search)\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Install\\anaconda\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn = KNN()\n",
    "iforest = IForest()\n",
    "xgbod = XGBOD()\n",
    "\n",
    "\n",
    "knn_params = { \"n_neighbors\": [1, 3, 5, 10],\n",
    "                \"method\": ['largest', 'mean'],\n",
    "                \"n_jobs\" : [-1]\n",
    "                }\n",
    "\n",
    "iforest_params = {\"n_estimators\": [50, 100, 200], \n",
    "                    'max_samples': [50, 100, 200],\n",
    "                    \"n_jobs\" : [-1],\n",
    "                    \"random_state\" : [0]\n",
    "                    }\n",
    "\n",
    "scale = np.sum(y_train == 1) / np.sum(y_train == 0)\n",
    "\n",
    "xgbod_params = {\"estimator_list\": estimator_list,\n",
    "                \"n_jobs\" : [-1],\n",
    "                \"random_state\" : [0],\n",
    "                \"scale_pos_weight\" : [1, scale, scale/2]\n",
    "                }\n",
    "\n",
    "knn_grid = {'model': [knn], 'param_grid': knn_params}\n",
    "iforest_grid = {'model': [iforest], 'param_grid': iforest_params}\n",
    "xgbod_grid = {'model': [xgbod], 'param_grid': xgbod_params}\n",
    "\n",
    "\n",
    "param_grids = [knn_grid, iforest_grid, xgbod_grid]\n",
    "\n",
    "grid_search_results = []\n",
    "\n",
    "for param_grid in param_grids:\n",
    "    model = param_grid['model'][0]\n",
    "    param_grid = param_grid['param_grid']\n",
    "    \n",
    "    grid_search = GridSearchCV(model, \n",
    "                               param_grid, \n",
    "                               cv=5, \n",
    "                               scoring=auprc, \n",
    "                               n_jobs=-1, \n",
    "                               verbose=2)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    grid_search_results.append(grid_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
